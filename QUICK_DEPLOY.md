# üöÄ ChatSpecies - Quick Deployment Guide

**3 Deployment Methods, Go Live in 10 Minutes!**

---

## üìã Pre-deployment Preparation

### Required API Keys

| API | Purpose | Get Address | Cost |
|-----|---------|-------------|------|
| **Qwen API** | LLM + TTS + Embeddings | [DashScope](https://dashscope.aliyun.com/) | Free tier available |
| **Supabase** | Interaction Log Storage | [Supabase](https://supabase.com/) | Free plan sufficient |

### Optional API Keys

| API | Purpose | Get Address | Cost |
|-----|---------|-------------|------|
| **Tavily** | High-quality Web Search | [Tavily](https://tavily.com/) | 1000 free searches/month |

---

## üéØ Method 1: Local Deployment (Windows) ‚≠ê Recommended for Beginners

### Step 1: Clone the Project
```bash
git clone https://github.com/your-username/zinos-chat.git
cd zinos-chat
```

### Step 2: Install Dependencies
```bash
# Using pip
pip install -r requirements.txt
```

### Step 3: Configure Environment Variables
```bash
# 1. Copy configuration template
copy config.env.template .env

# 2. Edit .env file, fill in your API Keys
notepad .env
```

**Required ConfigurationÔºö**
```env
DASHSCOPE_API_KEY=sk-your-qwen-key
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-key
```

**Optional ConfigurationÔºö**
```env
USE_WEB_SEARCH=true
WEB_SEARCH_PROVIDER=duckduckgo
TAVILY_API_KEY=tvly-your-key
OPENAI_API_KEY="your openai api key"
ENABLE_OPENAI_FALLBACK=false
AZURE_TTS_KEY="your azure tts key"
AZURE_TTS_REGION=westeurope
```

### Step 4: Set up RAG Knowledge Base
```bash
# One-click setup (Recommended)
setup_rag_system.bat

# Or execute manually
pip install tqdm
python vectorize_knowledge_base.py
```

**Wait 5-10 minute**Ôºåafter completion you should seeÔºö
```
‚úÖ ÂêëVector database created successfully!
üìä Statistics:
   - Document Count: 1298 blocks
   - Embedding Model: text-embedding-v3
```

### Enable Smart Web Search (Optional)
```bash
# Already included in requirements.txt, no additional action needed
# Web search functionality will be automatically enabled
```

### Run the Application
```bash
streamlit run main.py
```

**Visit**: http://localhost:8501

---

## üåê Method 2: Streamlit Cloud Deployment (Online Access)Ôºâ

### Step 1: Prepare GitHub Repository
```bash
# 1. Fork or push the project to your GitHub
git add .
git commit -m "Initial commit"
git push origin main
```

### Step 2: Deploy to Streamlit Cloud

1. Visit [Streamlit Cloud](https://share.streamlit.io/)
2. Click "New app"
3. Select your GitHub repository
4. ConfigureÔºö
   - **Main file path**: `main.py`
   - **Python version**: 3.11

### Step 3: Configure Secrets

On the Streamlit Cloud settings page, add the following Secrets:

```toml
# .streamlit/secrets.toml

# Required Configuration
DASHSCOPE_API_KEY = "sk-your-qwen-key"
SUPABASE_URL = "https://your-project.supabase.co"
SUPABASE_KEY = "your-supabase-key"

# Optional Configuration
USE_WEB_SEARCH = "true"
WEB_SEARCH_PROVIDER = "duckduckgo"
TAVILY_API_KEY = "tvly-your-key"
OPENAI_API_KEY="your openai api key"
ENABLE_OPENAI_FALLBACK=false
AZURE_TTS_KEY="your azure tts key"
AZURE_TTS_REGION="westeurope"

# Model Configuration
QWEN_MODEL_NAME = "qwen-turbo"
QWEN_EMBEDDING_MODEL = "text-embedding-v3"
QWEN_TTS_MODEL = "qwen3-tts-flash"
QWEN_TTS_VOICE = "Cherry"
```

### Step 4: Deploy and Test

1. Click "Deploy"
2. Wait for deployment to complete (approx. 2-3 minutes)
3. Visit your application link

---

## üêß Method 3: Linux/Mac Deployment

### Step 1: Clone the Project
```bash
git clone https://github.com/your-username/monkseal-chat.git
cd zinos-chat
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Python venv
python3 -m venv venv
source venv/bin/activate

# Or use conda
conda create -n zinos python=3.11
conda activate zinos
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment Variables
```bash
# Copy configuration template
cp config.env.template .env

# Edit configuration
nano .env
# or vim .env
```

### Step 5: Set up RAG Knowledge Base
```bash
pip install tqdm
python vectorize_knowledge_base.py
```

### Step 6: Enable Web Search (Optional)
```bash
pip install ddgs
```

Add to `.env` Ôºö
```env
USE_WEB_SEARCH=true
WEB_SEARCH_PROVIDER=duckduckgo
```

### Step 7: Run the Application
```bash
streamlit run main.py
```

---

## üß™ Post-deployment Testing

### 1. Basic Functionality Test

After accessing the application:
1. ‚úÖ Select languageÔºàEnglish/Portugu√™sÔºâ
2. ‚úÖ Enter questionÔºö"Hi, how are you?"
3. ‚úÖ Check AI response
4. ‚úÖ Check voice playback


### 2. RAG Quality Test
```bash
# Full test
python test_rag_quality.py

# Quick test
python test_user_questions.py
```

**Expected ResultsÔºö**
```
‚úÖ Vector Store Path: db5_qwen
‚úÖ Document Count: 1298
‚úÖ Retrieval Quality: Excellent (Coverage ‚â•75%)
```

### 3. Web Search Test
```bash
python test_smart_search.py
```

**Expected ResultÔºö**
```
‚úÖ Search query optimization normal
‚úÖ Result filtering normal (no technical/programming content)
‚úÖ All tests passed
```

---

## üîß Common Deployment Issues

### Issue 1: DDGS Package Error

**Error:**
```
DDGS.text() missing 1 required positional argument: 'query'
```

**SolutionÔºö**
```bash
# Uninstall old package, install new package
pip uninstall duckduckgo-search -y
pip install ddgs
```

---

### Issue 2: Empty Vector Database

**ErrorÔºö**
```
Document Count: 0
```

**SolutionÔºö**
```bash
# Ensure embedding model configuration is correct
# In .env:
QWEN_EMBEDDING_MODEL=text-embedding-v3

# Re-vectorize
python vectorize_knowledge_base.py
```

---

### Issue 3: Streamlit Cloud Deployment Failed

**ErrorÔºö**
```
ModuleNotFoundError: No module named 'ddgs'
```

**SolutionÔºö**
Ensure `requirements.txt` containsÔºö
```
ddgs
tavily-python
```

---

### Issue 4: Supabase Connection Failed

**ErrorÔºö**
```
Connection to Supabase failed
```

**SolutionÔºö**
1. Check if Supabase URL and Key are correct
2. Ensure database tables are created:
   - Run `create_table_interactions.sql`
   - Or create manually in Supabase Dashboard

---

## üìä Deployment Checklist

### Environment Configuration ‚úÖ

- [ ] Python 3.11+ installed
- [ ] All dependencies installedÔºà`pip install -r requirements.txt`Ôºâ
- [ ] `.env` file configured
- [ ] Qwen API Key valid
- [ ] Supabase URL and Key valid

### RAG System ‚úÖ

- [ ] Vector database createdÔºà`db5_qwen/`Ôºâ
- [ ] Document Count = 1298
- [ ] Embedding Model = text-embedding-v3
- [ ] RAG test passedÔºà`test_rag_quality.py`Ôºâ

### Web Search  ‚úÖ

- [ ] DDGS package correctly installed
- [ ] `USE_WEB_SEARCH=true` configured
- [ ] Search test passedÔºà`test_smart_search.py`Ôºâ

### Application Functionality ‚úÖ

- [ ] Application accessible normally
- [ ] Dialogue functionality normal
- [ ] Speech synthesis normal
- [ ] Fact-Check functionality normal
- [ ] Bilingual switching normal

---

## üöÄ Quick Command Reference

### Windows
```bash
# Complete deployment process
git clone <repo>
cd zinos-chat
pip install -r requirements.txt
copy config.env.template .env
# Edit .env to fill in API Keys
setup_rag_system.bat
streamlit run main.py
```

### Linux/Mac
```bash
# Complete deployment process
git clone <repo>
cd zinos-chat
pip install -r requirements.txt
cp config.env.template .env
# Edit .env to fill in API Keys
pip install tqdm ddgs
python vectorize_knowledge_base.py
streamlit run main.py
```

### Streamlit Cloud
```bash
# 1. Push to GitHub
git push origin main

# 2. Visit share.streamlit.io
# 3. Connect repository and configure Secrets
# 4. Click Deploy
```

---

## üìö Next Steps

After successful deployment:

1. **Experience Core Features**: Chat with species
2. **Test RAG Quality**: Run `test_rag_quality.py`
3. **Test Smart Search**: Run `test_smart_search.py`
4. **Read Full Documentation**: [docs/COMPLETE_GUIDE.md](docs/COMPLETE_GUIDE.md)
5. **Customize Configuration**: Adjust parameters in `.env` 

---

**Happy Deployment!** üéâ

[‚¨Ü Back to Top](#-chatspecies---quick_deploy)

